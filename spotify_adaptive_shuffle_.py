# -*- coding: utf-8 -*-
"""Spotify Adaptive Shuffle .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R89cZ5fmQMw9ucrvn01wkiX2_51_kcAQ
"""

!pip install kaggle

from google.colab import files
files.upload()  # This will prompt you to upload the kaggle.json file

import os
os.makedirs('/root/.kaggle', exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d yamaerenay/spotify-dataset-1921-2020-160k-tracks

!unzip -o spotify-dataset-1921-2020-160k-tracks.zip

import pandas as pd
df = pd.read_csv('data.csv')  # Adjust the filename if it's different (File names did not need to be adjusted)

# Check the first few rows
df.head()

# Overview of column names and data types
df.info()

"""Checking for Duplicates"""

# Group by song name and artist to check how often they repeat
dupes_by_name_artist = df.groupby(['name', 'artists']).size().reset_index(name='count')
dupes_by_name_artist = dupes_by_name_artist[dupes_by_name_artist['count'] > 1]

print(f"Potential duplicates by name + artist: {dupes_by_name_artist.shape[0]}")
dupes_by_name_artist.head(10)

# Find all entries for Lewis Capaldi
df[df['artists'].str.contains("Lewis Capaldi", case=False)].sort_values(by='name')

# Sort by popularity descending so we keep the most popular version first
df_sorted = df.sort_values(by='popularity', ascending=False)

# Drop duplicates based on name + artist, keeping the first (most popular version)
df_deduped = df_sorted.drop_duplicates(subset=['name', 'artists'], keep='first')

print(f"Original shape: {df.shape}")
print(f"After soft deduplication: {df_deduped.shape}")

"""Normalizing the Value of Audio Features"""

from sklearn.preprocessing import MinMaxScaler

# Define features to use in similarity comparisons
feature_cols = ['valence', 'energy', 'danceability', 'acousticness', 'instrumentalness',
                'liveness', 'speechiness', 'tempo']

# Normalize them using MinMaxScaler
scaler = MinMaxScaler()
df_deduped[feature_cols] = scaler.fit_transform(df_deduped[feature_cols])

# Just to verify:
df_deduped[feature_cols].describe()

"""Create Helper Matrix for Fast Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Create a NumPy matrix for fast similarity lookup
feature_matrix = df_deduped[feature_cols].values

# Reset index for easier tracking of song IDs
df_deduped = df_deduped.reset_index(drop=True)

# Tracking variables
played_indices = []
skipped_indices = []

"""Implemeting the Logic and Recommending Songs Based on Recent Plays"""

# Simulate a recent session history (played songs)
import random

n_recent = 10  # number of songs you want to simulate as played
played_indices = random.sample(range(len(df_deduped)), n_recent)

# Define the recommendation function
def recommend_songs(n_recent=10, top_k=5):
    if len(played_indices) == 0:
        print("No songs played yet.")
        return []

    # Use only the last `n_recent` played songs
    recent_indices = played_indices[-n_recent:] if len(played_indices) >= n_recent else played_indices

    # Calculate average feature vector
    avg_vector = np.mean(feature_matrix[recent_indices], axis=0).reshape(1, -1)

    # Find all unseen songs
    seen_indices = set(played_indices + skipped_indices) if 'skipped_indices' in globals() else set(played_indices)
    unseen_indices = [i for i in range(len(df_deduped)) if i not in seen_indices]

    if not unseen_indices:
        print("No unseen songs left.")
        return []

    unseen_matrix = feature_matrix[unseen_indices]

    # Compute cosine similarity
    similarities = cosine_similarity(avg_vector, unseen_matrix)[0]

    # Get top k matches
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    recommended_song_indices = [unseen_indices[i] for i in top_indices]

    return df_deduped.loc[recommended_song_indices]

# Get and display recommendations
recommendations = recommend_songs(n_recent=n_recent, top_k=5)
recommendations[['name', 'artists', 'popularity']]

# Show which songs were played (used for computing recommendation)
df_deduped.loc[played_indices][['name', 'artists', 'popularity']]

# Define the features to compare
feature_cols = ['valence', 'energy', 'danceability', 'acousticness',
                'instrumentalness', 'liveness', 'speechiness', 'tempo']

# Get feature vectors
played_features = df_deduped.loc[played_indices][feature_cols]
recommended_features = recommendations[feature_cols]

# Calculate the average feature vector for played songs
avg_played_vector = played_features.mean().values.reshape(1, -1)

# Calculate cosine similarity for each recommended song
from sklearn.metrics.pairwise import cosine_similarity

similarities = cosine_similarity(recommended_features, avg_played_vector)

# Display similarities for each recommended song
for i, score in enumerate(similarities):
    print(f"ðŸŽ§ Song {i+1} similarity to played profile: {score[0]:.4f}")

# Show overall feature-based accuracy
feature_accuracy = similarities.mean()
print(f"\nâœ… Feature-Based Accuracy Score: {feature_accuracy * 100:.2f}%")

"""Checking the Logic with Custom Input"""

def recommend_from_custom_input(played_ids, skipped_ids=None, top_k=5):
    played_indices = df_deduped[df_deduped['id'].isin(played_ids)].index.tolist()
    if skipped_ids:
        skipped_indices = df_deduped[df_deduped['id'].isin(skipped_ids)].index.tolist()
    else:
        skipped_indices = []

    # Compute average feature vector of played songs
    avg_vector = np.mean(feature_matrix[played_indices], axis=0).reshape(1, -1)

    # Remove seen songs
    seen = set(played_indices + skipped_indices)
    unseen_indices = [i for i in range(len(df_deduped)) if i not in seen]

    # Compute cosine similarity
    similarities = cosine_similarity(avg_vector, feature_matrix[unseen_indices])[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    recommended_indices = [unseen_indices[i] for i in top_indices]

    return df_deduped.loc[recommended_indices][['id', 'name', 'artists', 'popularity']]

# Define the function first
def get_song_ids_strict(matches):
    ids = []
    for title, artist in matches:
        result = df_deduped[
            df_deduped['name'].str.contains(title, case=False, na=False) &
            df_deduped['artists'].str.contains(artist, case=False, na=False)
        ]
        if not result.empty:
            print(f"\nMatch found for '{title}' by '{artist}':")
            display(result[['id', 'name', 'artists', 'popularity']].head(1))
            ids.append(result.iloc[0]['id'])
        else:
            print(f"\nNo match found for '{title}' by '{artist}'")
    return ids

# Now declare your test inputs
played_songs_exact = [
    ("There She Goes", "The La's"),
    ("Someone You Loved", "Lewis Capaldi"),
    ("I Won't Give Up", "Jason Mraz"),
    ("FourFiveSeconds", "Rihanna")
]

skipped_songs_exact = [
    ("Yellow", "Coldplay"),
    ("Hotline Bling", "Drake"),
    ("The Monster", "Rihanna")
]

# Now call the function safely
played_ids = get_song_ids_strict(played_songs_exact)
skipped_ids = get_song_ids_strict(skipped_songs_exact)

# Get recommendations
recommend_from_custom_input(played_ids, skipped_ids, top_k=5)

"""Checking Accuracy"""

# Get dataframes
played_df = df_deduped[df_deduped['id'].isin(played_ids)]
recommended_df = df_deduped[df_deduped['id'].isin(recommend_from_custom_input(played_ids, skipped_ids)['id'])]
skipped_df = df_deduped[df_deduped['id'].isin(skipped_ids)]

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Define features used in your recommender
feature_cols = ['valence', 'energy', 'danceability', 'acousticness',
                'instrumentalness', 'liveness', 'speechiness', 'tempo']

# Get feature vectors
played_vectors = played_df[feature_cols].values
recommended_vectors = recommended_df[feature_cols].values

# Average vector of played songs
avg_played_vector = np.mean(played_vectors, axis=0).reshape(1, -1)

# Compute similarity of each recommended song to the average played vector
similarities = cosine_similarity(recommended_vectors, avg_played_vector)

# Print similarity for each recommended song
for i, sim in enumerate(similarities):
    print(f"Song {i+1} similarity to played profile: {sim[0]:.4f}")

# Overall average similarity (can treat as "feature-based accuracy")
overall_similarity = np.mean(similarities)
print(f"\nFeature-Based Accuracy Score: {overall_similarity * 100:.2f}%")

# Define the same feature set you used in your recommender
features_to_compare = ['valence', 'energy', 'danceability', 'acousticness',
                       'instrumentalness', 'liveness', 'speechiness', 'tempo']

# Create a DataFrame with mean values for each group
import pandas as pd

metrics_df = pd.DataFrame({
    'Played': played_df[features_to_compare].mean(),
    'Recommended': recommended_df[features_to_compare].mean(),
    'Skipped': skipped_df[features_to_compare].mean() if not skipped_df.empty else None
})

# Transpose to make it readable
metrics_df = metrics_df.T
metrics_df

import matplotlib.pyplot as plt

metrics_df.T.plot(kind='bar', figsize=(12, 6))
plt.title('Audio Feature Comparison: Played vs Recommended vs Skipped')
plt.ylabel('Normalized Feature Value')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()